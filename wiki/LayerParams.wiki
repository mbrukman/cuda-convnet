#summary Describes format of layer definition and parameter files.

= Introduction =

To define the architecture of your neural net, you must write a layer definition file. Here I will go through the format of the file and the parameters that the different layers take.


= File format =

Let's start with an example. The very first thing we'll define is a data layer:

{{{
[data]
type=data
dataIdx=0

[labels]
type=data
dataIdx=1

# By the way, this is a comment.
}}}

The things in square brackets are user-friendly layer names, and they can be whatever you want them to be. Here we're really defining two layers: one we're calling "data" and the other we're calling "labels". 

The *type=data* line indicates that this is a data layer. Our python DataProvider (CIFARDataProvider) outputs a list of two elements: the CIFAR-10 images and the CIFAR-10 labels. 

The line *dataIdx=0* indicates that the layer named *data* is mapped to the CIFAR-10 images (and the layer named *labels* is mapped to the CIFAR-10 labels).

Now let's apply a convolution to this data.

{{{
[conv32]
type=conv
inputs=data
channels=3
numFilters=32
padding=4
stride=1
filterSize=9
neuron=logistic
initW=0.00001
partialSum=1
}}}

Again, the bracketed conv32 is the name we're choosing to give to this layer.

Here's what the other parameters mean:
  * *type=conv* defines this as a convolution layer
  * *inputs=data* says that this layer will take as input the layer named *data* (defined above)
  * *channels=3* tells the net that the layer named *data* produces 3-channel images (i.e. color images). Since the images are assumed to be square, that is all that you have to tell it about the data dimensionality.
  * *numFilters=32* says that this layer will apply 32 filters to the images.
  * *padding=4* instructs the net to implicitly pad the images with a 4-pixel border of zeros (this does not cause it to create a copy of the data or use any extra memory). Set to 0 if you don't want padding.
  * *stride=1* indicates that the distance between successive filter applications should be 1 pixel.
  * *filterSize=9* says that this layer will use filters of size 9x9 pixels.
  * *neuron=logistic* defines the neuron nonlinearity. See NeuronTypes for supported types.
  * *initW=0.00001* instructs the net to initialize the weights in this layer from a normal distribution with standard deviation 0.00001.
  * *partialSum=1* is a very important parameter if you care about performance. Keep it at 1 for maximum performance at the expense of memory consumption. Set it to higher numbers (up to the number of outputs that your convolution produces) to gradually trade memory consumption for performance. Setting it to 0 is equivalent to setting it to the highest (i.e. slowest, but least memory-hungry) number possible. In most scenarios there should be no problem to keep this parameter at 1. To give you an idea of what effect it will have on memory consumption: the amount of extra memory used will be:
  `(number of weights in this layer)x(number of outputs this layer produces) / partialSum.`

For kicks, let's add a fully-connected layer over the data too:
{{{
[fc1024]
type=fc
numOutputs=1024
inputs=data
initW=0.001
neuron=relu
}}}

The only parameter here that I have not already described above is *numOutputs=1024*. It does what you would expect -- it indicates that this layer should have 1024 units.

Back to convolution now, let's add a max-pooling layer over our convolution layer.

{{{
[maxpool]
type=pool
pool=max
inputs=conv32
start=0
subsX=4
stride=2
outputsX=0
channels=32
}}}

A few new parameters here:
  * *pool=max* indicates that this is to be a max-pooling layer. Also supported is *pool=avg*.
  * *inputs=conv32* indicates that this layer subsamples the layer named *conv32*.
  * *start=0* tells the net where in the image to start the pooling. In principle, you can start anywhere you want. Setting this to a positive number will cause the net to discard some pixels at the top and at the left of the image. Setting this to a negative number will cause it to include pixels that don't exist (which is fine). *start=0* is the usual setting.
  * *subsX=4* defines the size of the pooling region in the x (equivalently, y) dimension. Squares of size (*subsX*)^2^ get reduced to 1 value by this layer.
  * *stride=2* defines the stride size between successive pooling squares. Setting this parameter smaller than *subsX* produces _overlapping_ pools. Setting it equal to *subsX* gives the usual, non-overlapping pooling.
  * *outputsX=0* allows you to control how many outputs in the x (equivalently, y) dimension this operation should have. This parameter is analogous to the *start* parameter, in that it allows you to discard some portion of the image by setting it to a value small enough to leave part of the image uncovered. Setting it to 0 instructs the net to produce as many outputs as is necessary to ensure that the whole image is covered.

OK, let's add one more convolutional layer over the pooling layer:

{{{
[conv32-2]
type=conv
inputs=maxpool
numFilters=32
padding=2
stride=1
filterSize=5
channels=32
neuron=relu
initW=0.0001
partialSum=1
}}}

Nothing new here. Notice that this convolutional layer has 32 channels, because the *conv32* layer (and hence the *maxpool* layer) produces images with 32 channels.

Now let's connect this convolutional layer and the fully-connected layer defined long ago to a softmax output:
{{{
[fc10]
type=fc
numOutputs=10
inputs=conv32-2,fc1024
initW=0.001
neuron=ident

[probs]
type=softmax
inputs=fc10
}}}

The main point of this example is to illustrate that a fully-connected layer can take multiple inputs. Here *fc10* is taking input from *conv32-2* and *fc1024*, and produces 10 outputs.

The next definition is a softmax layer that, as you might expect, applies a softmax to the 10 outputs produced by the *fc10* layer.

Finally, let's define an objective function for the net to optimize:

{{{
[logprob]
type=cost.logreg
inputs=labels,probs
}}}

The *cost.logreg* objective takes two inputs -- labels and predicted probabilities. We defined the *labels* layer early on, and the *probs* layer just above.

That's it! The convolutional net is defined.