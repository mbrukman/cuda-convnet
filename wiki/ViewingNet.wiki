#summary How to look inside the checkpoints saved by the net.

<h1>Table of Contents</h1>
<wiki:toc max_depth="3" />

= Introduction =

Included with this code is a very basic script called [http://code.google.com/p/cuda-convnet/source/browse/trunk/shownet.py shownet.py]. It has two functions: to plot the training/test error and to draw the filters that the neural net learned.

This script requires the [http://matplotlib.sourceforge.net/ matplotlib] python library (package name `python-matplotlib` in Ubuntu and Fedora).

= Details =

As mentioned above, [http://code.google.com/p/cuda-convnet/source/browse/trunk/shownet.py shownet.py] has two functions, which I will demonstrate by example.

==Plotting the cost function==
To plot the evolution of the value of some cost function over time, call the script like this:

{{{
python shownet.py -f /storage2/tmp/ConvNet__2011-08-24_16.49.31 -e logprob
}}}

The parameter to `-f` is the checkpoint location (which is printed out repeatedly by `convnet.py` during training); the parameter to `-e` is the name that we gave to the cost function in the layer configuration file (see [LayerParams#Logistic_regression_cost_layer]).

You should see output that looks something like this:

http://cuda-convnet.googlecode.com/svn/wiki/images/cost-function.png

which plots the training and test error over time.

==Viewing learned filters==
To view the filters that the net learned, call the script like this:
  
{{{
python shownet.py -f /storage2/tmp/ConvNet__2011-08-24_16.49.31 -l conv32
}}}
  
The parameter to `-l` is the name of the layer whose filters we wish to view, defined in the layer configuration file (see [LayerParams#Convolution_layer]).

You should see output that looks something like this:

http://cuda-convnet.googlecode.com/svn/wiki/images/filters.png

Note that you're not likely to get such pretty filters in higher layers. So this visualization is mostly useful only for looking at data-connected layers.

You'll notice that the script has interpreted the 3 channels in the conv32 layer as RGB color channels. It will only do this for layers that have 3 channels. If the RGB assumption is incorrect (i.e. your 3 channels correspond to something other than RGB colors), you can use the *-o* option to instruct the script not to combine the channels. It will then plot the channels separately.

An example:

{{{
python shownet.py -f /storage2/tmp/ConvNet__2011-08-24_16.49.31 -l conv32 -o
}}}

will produce output that looks like this:

http://cuda-convnet.googlecode.com/svn/wiki/images/filters-separated.png

Here the 3 channels of each filter are plotted side-by-side in grayscale.

===Viewing learned filters in fully-connected layers===
There are two meta-parameters that the `-l` parameter takes, which are only useful for viewing filters in fully-connected layers. Again I will demonstrate their use by example.
  
Running the script like this:

{{{
python shownet.py -f /storage2/tmp/ConvNet__2011-08-24_17.56.48 -l fc64 -i 0 -c 3
}}}

produces output that looks like this:

http://cuda-convnet.googlecode.com/svn/wiki/images/filters-fc.png

Here the layer name fc64 given to the `-l` option refers to a fully-connected layer. The two extra parameters are described below.

|| *Parameter* || *Meaning* ||
|| `-c 3` || Specifies the number of channels that the filters have. This has to be given because a fully-connected layer looks upon its input as completely flat. It is not aware of channels or image dimensions, etc. ||
|| `-i 0` || Specifies the input index for which to plot filters. Remember that fully-connected layers can take multiple inputs, so this parameter removes that ambiguity. ||

=Epilogue=
The script described here is very basic. It performs few error checks, and hence will produce stack traces if something goes wrong. But maybe that will make it clearer how to modify it to fit your needs.