#summary How to look inside the checkpoints saved by the net.

<h1>Table of Contents</h1>
<wiki:toc max_depth="3" />

= Introduction =

Included with this code is a basic script called [http://code.google.com/p/cuda-convnet/source/browse/trunk/shownet.py shownet.py]. It has three functions:
  * to plot the training/test error over time,
  * to display the filters that the neural net learned, and
  * to show the predictions (and errors) made by the net.

This script requires the [http://matplotlib.sourceforge.net/ matplotlib] python library (package name `python-matplotlib` in Ubuntu and Fedora).

= Details =

==Plotting the cost function==
To plot the evolution of the value of some cost function over time, call the script like this:

{{{
python shownet.py -f /storage2/tmp/ConvNet__2011-08-24_16.49.31 --show-cost=logprob
}}}

This will cause the script to open the latest checkpoint at `/storage2/tmp/ConvNet__2011-08-24_16.49.31` and to plot the cost function named `logprob` (which is the name that we happened to give to the cost layer -- see [LayerParams#Logistic_regression_cost_layer]).

You should see output that looks something like this:

http://cuda-convnet.googlecode.com/svn/wiki/images/cost-function.png

which plots the training and test error over time.

==Viewing learned filters==
To view the filters that the net learned, call the script like this:
  
{{{
python shownet.py -f /storage2/tmp/ConvNet__2011-08-24_16.49.31 --show-filters=conv32
}}}
  
This will cause the script to draw the filters in the layer named `conv32`. You should see output that looks something like this:

http://cuda-convnet.googlecode.com/svn/wiki/images/filters.png

Note that you're not likely to get such pretty filters in higher layers. So this visualization is mostly useful only for looking at data-connected layers.

You'll notice that the script has interpreted the 3 channels in the `conv32` layer as RGB color channels. It will only do this for layers that have 3 channels. If the RGB assumption is incorrect (i.e. your 3 channels correspond to something other than RGB colors), you can use the `--no-rgb=1` option to instruct the script not to combine the channels. It will then plot the channels separately.

An example:

{{{
python shownet.py -f /storage2/tmp/ConvNet__2011-08-24_16.49.31 --show-filters=conv32 --no-rgb=1
}}}

will produce output that looks like this:

http://cuda-convnet.googlecode.com/svn/wiki/images/filters-separated.png

Here the 3 channels of each filter are plotted side-by-side in grayscale.

===Viewing learned filters in fully-connected layers===
There are two meta-parameters that the `-l` parameter takes, which are only useful for viewing filters in fully-connected layers. Again I will demonstrate their use by example.
  
Running the script like this:

{{{
python shownet.py -f /storage2/tmp/ConvNet__2011-08-24_17.56.48 --show-filters=fc64 --input-idx=0 --channels=3
}}}

produces output that looks like this:

http://cuda-convnet.googlecode.com/svn/wiki/images/filters-fc.png

Here the layer name fc64 given to the `--show-filters` option refers to a fully-connected layer. The two extra parameters are described below.

|| *Parameter* || *Meaning* ||
|| `--channels=3` || Specifies the number of channels that the filters have. This has to be given because a fully-connected layer looks upon its input as completely flat. It is not aware of channels or image dimensions, etc. ||
|| `--input-idx=0` || Specifies the input index for which to plot filters. Remember that fully-connected layers can take multiple inputs, so this parameter removes that ambiguity. ||

==Viewing test case predictions==

To see the predictions that the net makes on test data, run the script like this:

{{{
python shownet.py -f /storage2/tmp/ConvNet__2011-08-24_17.56.48 --show-preds=1 --logreg-name=logprob
}}}

Notice that we have to specify the name of the logistic regression cost layer to the `--logreg-name` parameter.

You should see output that looks like this:

http://cuda-convnet.googlecode.com/svn/wiki/images/test-preds.png

This shows 8 random images from the test set, their true labels, and the 4 labels considered most probable by the model. You can see that in this case the model only got one of the images wrong.

To show _only_ the mis-classified images, run the script like this:

{{{
python shownet.py -f /storage2/tmp/ConvNet__2011-08-24_17.56.48 --show-preds=1 --logreg-name=logprob --only-errors=1
}}}

Now the script will only show images for which the true label is different from the model's most-probable label.